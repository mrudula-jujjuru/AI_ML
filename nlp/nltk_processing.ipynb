import re
import nltk
nltk.download('punkt_tab') 
txt = """Beans. I was trying to explain to somebody as we were flying in, that's corn. That's beans. And they were very impressed..."""
# Tokenize sentences
sentences = nltk.sent_tokenize(txt)
# Process in one pass using list comprehension
dataset = [
    re.sub(r'\s+', ' ', re.sub(r'\W', ' ', sentence.lower())).strip()
    for sentence in sentences
]

# Display results
for i, sentence in enumerate(dataset, 1):
    print(f"Sentence {i}: {sentence}")


